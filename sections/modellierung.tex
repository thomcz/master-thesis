%% LaTeX2e class for student theses
%% sections/evaluation.tex
%% 
%% Karlsruhe Institute of Technology
%% Institute for Program Structures and Data Organization
%% Chair for Software Design and Quality (SDQ)
%%
%% Dr.-Ing. Erik Burger
%% burger@kit.edu
%%
%% Version 1.3.3, 2018-04-17

\chapter{Modellierung}
\label{ch:modellierung}
Wie bereits in \autoref{sec:eventbasetransformation} beschrieben bietet das PCM die Möglichkeit eventbasierte Kommunikation zu modellieren und auch eine konkrete MOM Architektur zu modellieren, die mithilfe einer Modelltransformation in die Systemarchitektur eingewoben wird. Diese Modellierung hat jedoch das Problem, dass die Kommunikation nur in eine Richtung funktioniert, wie in (ABB) zu sehen. Ein Sender sendet eine Nachricht an einen Empfänger und auf dem Weg dorthin durchläuft die Nachricht eine Komponentenkette und wird mit bestimmten Ressourcenanforderungen belegt. Der Empfänger erhält schließlich die Nachricht. In diesem Szenario fehlt jedoch die Warteschlange, die eine wichtige Komponente einer MOM ist. Eigentlich sollte die Komunikation wie in (ABB) abgebildet stattfinden. Der Sender sendet die Nachricht an die MOM, diese leitet die Nachricht an die entsprechende Warteschlange weiter und ein Empfänger holt sich die Nachricht ab, sobald er die Ressourcen dazu hat. Dieses Szenario ist mit der aktuellen eventbasierten Kommunikation in PCM nicht darstellbar, weil kein abholen einer Nachricht vorgesehen ist. Deshalb soll im Folgenden eine Modellierung präsentiert werden, die eine explizite Warteschlange und ein Verteilsystem, das Nachrichten an passenden Warteschlangen verteilt, modelliert.\par
Dazu soll zunächst mithilfe einer Anforderungserhebung in \autoref{sec:anforderungserhebung} Anforderungen gesammelt werden, die eine solche Modellierung erfüllen soll. Im Anschluss wird in \autoref{sec:modell} die Modellierung einer MOM vorgestellt, die die Anforderungen erfüllen soll. In \autoref{sec:modellkalibrierung} soll das Modell mithilfe der in \autoref{sec:rmqBenchmark} ausgemessenen MOM RMQ kalibriert werden. Dabei soll ein kalibrierter MOM Baustein entstehen, der sich wie die ausgemessene MOM verhalten soll. Schließlich wird in \autoref{sec:momsimulation} das MOM Modell in mehreren Simulationen eingesetzt werden und mit den realem Messungen verglichen. 

\section{Anforderungserhebung}
\label{sec:anforderungserhebung}
Aus der Definition einer MOM (siehe Grundlagen) und den Messungen aus \autoref{ch:mom} wurden die folgenden Anforderungen an eine Modellierung abgeleitet. Dabei wurde unterschieden zwischen technischen Anforderungen, also was die Modellierung leisten muss und Anforderungen an die Nutzbarkeit unterschieden. 
Zu den technischen Anforderungen gehören:
\begin{itemize}
    \item Die Modellierung soll das allgemeine Verhalten einer MOM abbilden können.
    \item Asynchrones senden und empfangen von Nachrichten.
    \item Es soll möglich sein eine Nachricht an eine bestimmte Warteschlange oder Topic senden zu können.
    \item Der Füllstand der Warteschlange soll mithilfe der Performanzanalyse ermittelt werden können.
    \item Die Latenz einer Nachricht soll mithilfe der Performanzanalyse ermittelt werden können.
\end{itemize}
Der Benutzer der Modellierung muss in der Lage sein die Folgenden Dinge angeben zu können:
\begin{itemize}
    \item Die Nachrichtengröße muss definierbar sein
    \item Die Topic einer Nachricht muss definierbar sein
    \item Die Anzahl der Nachrichten die pro Sekunde gesendet werden muss angegeben werde können
\end{itemize}

%Angabe des Durchsatzes \\


%Das Ziel ist es eine allgemeine MOM Modellierung zu erstellen, die das Verhalten einer MOM abbilden kann. Dabei soll nicht Wert auf ein spezielles Verhalten gelegt werden. Stattdessen soll es moeglich sein die Modellierung um Konfigurationen, wie zum Beispiel RMQs lazy Queues, erweitern zu koennen. 

\section{Modell}
Im Folgenden soll eine Modellierung einer MOM präsentiert werden die die zuvor definierten Anforderungen erfüllt. Dabei war nicht das Ziel eine Meta-Modell Erweiterung zu erstellen, sondern mit bereits existierenden PCM-Elementen zu arbeiten. 

%Anhand der bekannten MOM Architekturen aus der Untersuchung verschiedener MOMs wurde versucht zu definieren wie eine MOM modelliert werden kann. Dabei wurden die Anforderungen versucht umzusetzen. \\
%- 2 Moeglichkeiten entweder mit oder ohne Exchange explizit zu modellieren.\\
%- Vorteil Explizit: RDs fuer verteilung (konnte aber nicht ausgemessen werden) \\
%- Nachrichten Typen mitschicken (fanout, direct) und in Branches auswerten

\subsection{Repository}
Das Repository wird vom Komponentenentwickler verwendet um neue Komponenten zu erstellen und vom Systemarchitekt um Komponenten zu entnehmen. ... \\
Die untersuchte MOM Architektur besteht aus einem Verteiler und einer Warteschlange. Deshalb wurdem die in \autoref{img:mom_repository} abgebildeten Komponenten und Schnittstellen definiert. Die Schnittstelle nach ausen soll die IExchange Schnittstelle sein. Diese bietet zwei Signaturen an. Eine zum Empfange (receive) und eine zum Senden (distribute) einer Nachricht. Beide Methoden werden von der Komponente Exchange angeboten. IQueue ist die zweite Schnittstelle. Diese bietet auch zwei Signaturen an. Eine um eine Nachricht in eine Warteschlange abzulegen (put) und eine weitere die eine Nachricht aus der Warteschlange entnimmt (get). Diese Schnittstelle wird von der Komponente Queue angeboten. Diese Komponenten, die eine Warteschlange abbildeen soll, besitzt eine Passive Resource die das Verhalten einer Warteschlange simulieren soll. Eine Passive Ressouce ist... (TODO). Dabei wird das ablegen in die Warteschlange als release auf die passive Ressource und das entnehmen aus der Warteschlange als aquire auf die passive Ressource modelliert. Die Exchange Komponente benötigt eine Komponente die die IQueue Schnittstelle anbietet. Die Idee ist, dass alle Warteschlangen die benötigt werden von der Exchange Komponente required werden. In \autoref{img:mom_repository} sind das aktuell zwei Warteschlange. Mithilfe des RDSEFFs kann die Exchange Komponente zwischen den Warteschlangen wechseln. Dies ist in (Abb) dargestellt. Dabei wird mithilfe eines GuardedBranch geprüft an welche Warteschlange die ankommenden Nachricht gehen soll. Der Fall, dass eine Nachricht aus der Warteschlange entnommen wird funktioniert genauso. 


%Dieser Ansatz ermöglicht es jedoch nicht einzelne Nachrichten durch das System zu verfolgen. \\


\begin{figure}
\center
  \includegraphics[width=1\textwidth]{images/mom_repository.png}
  \caption{Repository einer MOM mit Exchange und Warteschlange}
  \label{img:mom_repository}
\end{figure}

\subsection{System}
Im System werden Queues mit dem Exchange \autoref{img:mom_system}\\
Sender und Empfaenger werden jeweils an den Exchange angeschlossen. Fuer Senden und Empfangen jeweils eine Porivided Role.

\begin{figure}
\center
  \includegraphics[width=1\textwidth]{images/mom_system.png}
  \caption{Systemmodell mit einer MOM und einem Sender und Empfänger}
  \label{img:mom_system}
\end{figure}

\subsection{Usage}
Benutzer gibt an ob er empfangen oder senden will. \\
Benutzer gibt an welche Queue/Topic er wie viel Byte senden/empfangen moechte. \\
Ankunftsrate als Hebel um Sende-Empfangrate abzubilden \\
\subsection{Ressource Environment und Allokation}
Einen Server fuer Exchange \\
Jede Queue kann auf anderer Ressource deployed sein. die am Ende mit dem Exchange Server verbunden sein muss.\\
Fuer LR kann RD angegeben werden.

\section{Ressource Demands}
\subsection{RMQ}
\label{sec:rmqRd}
Fuer RDs wurden die Messungen aus (Benchmarks) herangezogen. \\ 
Das Ziel ist, dass der Benutzer keinen MOM spezifischen RD angeben muss. \\
In \autoref{sec:maxthroughput} wurde gemessen, was die moegliche Datenmenge ist, die gesendet werden kann (Durchsatz). Dieser Wert wird im Ressource Environment in die jeweiligen Linking Ressources eingetragen. Dabei wird fuer den LR zwischen Sender und MOM der Wert fuer keine Empfaenger eingetragen und fuer die LR zwischen Empfaenger und MOM der Wert fuer mit Empfaenger. \\

Latenz einer Nachricht mit verschiedener Bytegroesse wurde ausgemessen (siehe latenz verschiedenen Msg größen). Mithilfe einer Regressionsanalyse konnte ein RD der Form (7 * (msg.BYTESIZE + 110588)) / 489 identifiziert werden.\\

Wo Nachrichten hingeschrieben wurden waren auch ein wichtiger Einflussfaktor. Fuer eine Nachricht der Groesse x konnte ein RD der Form e * x / 1000 identifiziert werden. Dieser wurde aus der Differenz der Messungen mit und ohne LazyQueues errechnet. \\

Falls die Netzwerklatenz betrachtet werden soll, kann diese in der jeweiligen LR eingetragen werden.\\

Als Eingabe fuer das System soll im Usage Modell die zu sendende Nachrichtengroesse mithilfe einer UsageVariable und der Characteristic: Bytesize angegeben werden.\\

Die Anzahl an Nachrichten die gesendet oder empfangen werden koennen werden ueber die Ankuftzeit gesteuert.\\
ArrivalTime / Anzahl Msgs \\
oder einfach BYTESIZE = Bytesize * Anazahl Nachrichten \\

- TODO: tabelle mit Werten fuer alle RDs\\

Somit sollte sich fuer die Response Time folgendes ergeben: Response Time: ByteSize / Throughput + RD / CPU + Latency + HddRD/HDD \\
%RD an Aquire um Latenz abzubilden

%Als erstes sollte die Sende und Empfangsrate abgebildet werden. Beobachtet man (ref zu Messung verschiedene Senderaten) bemerkt man fuer die ersten Messungen, solange Warteschlange nicht allzu voll wird, einen linearen Anstieg der Latenz. Daraus laesst sich zunaechst folgender RD ableiten:






%Latenz: Unter Latenz versteht man im MOM Kontext, die Zeit, die eine einzelne Nachricht braucht um beim Consumer anzukommen. Da jede Nachricht einen Zeitstempel bekommt kann die Zeit gemessen werden, wenn sie aus der Warteschlange entnommen wurde.

%welche Effekte koennen wir so hoffentlich abbilden
\subsection{Kafka}

\section{Untersuchung der MOM Bausteine}
In diesem Abschnitt sollen die Bausteine in bestimmten Szenarien ueberprueft werden. Dabei sollen die Simulations- und Messergebnisse aus \autoref{sec:mom} verglichen werden.
\subsection{RMQ}
Im Folgenden betrachten wir das in (Abb) abgebildete Szenario. Darin befindet sich ein Sender und ein Empfaenger. Der Sender sendet pro Zeiteinheit und der Empfaenger empfaengt pro Zeiteinheit eine bestimmte Menge an Daten. Dieses Szenario soll den Benchmark widerspiegeln, der fuer das ausmessen von RMQ in \autoref{sec:rmqBenchmark} verwendet wurde.




\subsubsection{Simulation 1} 
\label{sec:rmqSimulation1}
In der ersten Simulation betrachten wir den Fall, dass Sender und Empfaenger die gleichen Ankunftszeiten haben. Die gesendete Nachrichten haben die groessen 100, 200, 300, 400, 500 und 1000 Kbyte. Verglichen wurde mit den Messungen aus \autoref{sec:oneMsgLatency}. Der Sender, Empfaenger und der Broker befinden sich jeweils auf der selben Maschine. Betrachtet wurden der Fuellstand der Warteschlange und die Latenz der Nachrichten. 
%B
Da die Ankunftszeiten der beiden Akteure gleich sind, bleibt die Warteschlange die ganze Zeit ueber Leer. Die Ergebnisse der Latenz einer Nachricht sind in \autoref{img:simulation1} abgebildet. ...

\begin{figure}
\center
  \includegraphics[width=0.5\textwidth]{images/modelSimulationResults/simulation1.png}
  \caption{Latenz einer Nachricht mit verschiedenen Groessen (Modell vs. Real System)}
  \label{img:simulation1}
\end{figure}

\subsubsection{Simulation 2} 
Diese Simulation betrachtet zusaetzlich zu dem Fall aus Simulation 1 die Netzwerklatenz mit. Dazu sind Sender, Empfaenger und Broker auf unterschiedlichen Maschinen. Die Nachrichten haben wieder die groessen 100, 200, 300, 400, 500 und 1000 Kbyte. Im Modell wurden fuer die LinkingRessources der Durchsatz und die Latenz, wie in \autoref{sec:rmqRd} beschrieben, angepasst. Die Messung mit der verglichen wurde ist in \autoref{sec:oneMsgLatency} beschrieben. Auch bei diesem Vergleich wurde der Fuellstand der Warteschlange und die Latenz der Nachrichten betrachtet. 
%B
Auch hier bleibt die Warteschlange leer, da die Ankuftszeiten der Sender und Empfaenger gleich sind. Die Latenz der Nachrichten ist in \autoref{img:simulation2} abgebildet. 
\begin{figure}
\center
  \includegraphics[width=0.5\textwidth]{images/modelSimulationResults/simulation2.png}
  \caption{Latenz einer Nachricht mit verschiedenen Groessen mit Netzwerklatenz (Modell vs. Real System)}
  \label{img:simulation2}
\end{figure}


\subsubsection{Simulation 3}
In dieser Simulation soll geprueft werden ob sich Modell und Real System bei unterschiedlichen Ankuftszeiten gleich verhalten. Dabei ist die Ankuftszeit des Senders jede Sekunde und die des Empfangers alle zwei Sekunde. Der Fuellstand der Warteschlange wird ueber die Zeit betrachtet. Verglichen wurde mit der Messung aus \autoref{sec:queueGrowth}.
%B
Die Ergebnisse sind in \autoref{img:simulation3} abgebildet. Dabei ist zu sehen, dass sich Messung und Simulation gleich verhalten und ueber die Zeit ansteigen.
\begin{figure}
\center
  \includegraphics[width=0.5\textwidth]{images/modelSimulationResults/simulation3.png}
  \caption{Anwachsen der Warteschlange (Modell vs. Real System)}
  \label{img:simulation3}
\end{figure}

\subsubsection{Simulation 4}
Bei der folgenden Simulation ist die Ankuftszeit des Senders jede Sekunde und die des Empfangers alle zwei Sekunden. Im Unterschied zur vorherigen Simulation gibt es einen weiterern Empfaenger, der auch jede zweite Sekunde ankommt. Ziel dieser Simulation soll sein, zu pruefen ob zwei Empfaenger die Warteschlange zusammen abarbeiten koennen, wie es auch im realen System ist, wie in \autoref{sec:varyingConsumer} beschriebenen.
%B
\autoref{img:simulation4} zeigt den Zustand der Warteschlange ueber die Zeit. Im Unterschied zu \autoref{img:simulation3}, bekommen die beiden Empfaenger die Warteschlange gemeinsam abgearbeitet.

\begin{figure}
\center
  \includegraphics[width=0.5\textwidth]{images/modelSimulationResults/simulation4.png}
  \caption{Gemeinsames Abarbeiten einer Warteschlange durch zwei Empfaenger (Modell)}
  \label{img:simulation4}
\end{figure}

%Simulation 5: \\
%- Max Durchsatz \\
%- eine Nachricht mit max Bytesize schicken \\
%-> Response time sollte kontinuirlich ansteigen \\


\subsubsection{Simulation 5}
Die letzte Simulation betrachtet den Fall von Lazy Warteschlangen in RMQ. Sender und Empfaenger haben die gleiche Ankunftszeiten und die gesendete Nachrichten haben die Groessen 100, 200, 300, 400, 500 und 1000 Kbyte. Der RD fuer eine Nachricht wurde erweitert. Dieser ist in \autoref{sec:rmqRd} beschrieben. Erwartet wird, dass die Latenz im Vergleich zu \autoref{sec:rmqSimulation1} ansteigt. Verglichen wurde mit der Messung aus \autoref{sec:rmqLazy}.
%B
Die Ergebnisse sind in \autoref{img:simulation6} abgebildet. Wie zu erwarten steigt die Latenz an. Im Vergelich zur realen Messung liegt der Unterschied bei x Prozent.
\begin{figure}
\center
  \includegraphics[width=0.5\textwidth]{images/modelSimulationResults/simulation6.png}
  \caption{Latenz einer Nachricht mit verschiedenen Groessen bei Lazy Warteschlangen (Modell vs. Real System)}
  \label{img:simulation6}
\end{figure}


\subsection{Kafka}

\section{Grenzen}
Dieser Ansatz ermöglicht es jedoch nicht einzelne Nachrichten durch das System zu verfolgen\\

welche Moeglichkeiten gibt es? Dominiks Queue Modell. Direkt drauf verweisen, oder eine/diese Idee beschreiben.\\
%Queue Fuellstand ist unbekannt \\

%Nachdem eine MOM in das Experimentsystem eingebaut wurde, soll sie im Anschluss in Palladio modelliert werden. Wie bereits erwähnt existiert eine Palladio Modellierung des Experimentsystem, auf der aufgebaut werden kann. Bei der Modellierung der MOM soll zunächst die Standardkonfiguration und in späteren Iterationen Parametrisierbarkeit modelliert werden. Dazu soll zunächst versucht werden die MOM mithilfe vorhandener PCM Elementen zu modellieren und Unzugänglichkeiten zu identifizieren. Die Idee ist, mithilfe von Architecture-Templates \cite{architcturetemplate} diese Unzugänglichkeiten zu beseitigen. Dabei handelt es sich um wiederverwendbare Muster, die auf Palladio-Modelle angewendet werden können. Beispielsweise kann anstelle der manuellen Modellierung eines Lastverteilers auch das Architectural-Template für Lastverteiler verwendet werden. %Da diese Anwendung nur aus wenigen kleinen Schritten besteht, können Architekten viel Modellierungsaufwand einsparen.


%(-- RabitMQ Config:)\\% https://www.rabbitmq.com/configure.html\\
%(-- Kafka Config:)\\ %https://kafka.apache.org/documentation/#brokerconfigs 

