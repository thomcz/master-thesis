%% LaTeX2e class for student theses
%% sections/content.tex
%% 
%% Karlsruhe Institute of Technology
%% Institute for Program Structures and Data Organization
%% Chair for Software Design and Quality (SDQ)
%%
%% Dr.-Ing. Erik Burger
%% burger@kit.edu
%% burger@kit.edu
%%
%% Version 1.3.3, 2018-04-17


\chapter{Untersuchung von nachrichtenbasierter Middleware}
\label{ch:mom}
Um die Performance einer MOM, oder eines Software-Systems im Allgemeinen, vorhersagen zu können, benötigt man zunächst Informationen über die Struktur des Systems, sein Verhalten, seine Ausführungsumgebung und über die Benutzung. Dazu müssen die verschiedenen Palladio-Rollen relevante Einflüsse bestimmen können. Der \\ Komponenten-Entwickler muss Ressourcen-Anforderungen und Fehlerraten bestimmen. Der Software-Verteilungs-Experte muss verfügbare Rechenleistung und Hardware bestimmen. Der Domänenexperte muss das Verhalten der Nutzer bestimmen. Schließlich muss der Softwarearchitekt fehlende Werte bestimmen und das Modell damit kalibrieren. Diese Modellkalibrierung ist ein wichtiger Bestandteil des Modellierungsprozesses. In \cite{palladio17} wird beschrieben, wie und mit welchen Techniken die verschiedenen Rollen diese Daten erhalten und die jeweiligen Modelle kalibrieren können. Modellkalibrierung ist dabei die Anreicherung von Modellen mit quantitativen Daten, wie Ressourcenbedarf. Die Daten können aus Messungen oder Vorhersagen stammen. Die Modellkalibrierung ist eine Vorbedingung der Performance-Analyse. Die Informationen, die eine Rolle in den verschiedenen Phasen der Software-Entwicklung gewinnen kann, sind unterschiedlich. Dieser Prozess lässt sich in drei Aktivitäten strukturieren: Design, Entwicklung und Betrieb. Während der Design-Aktivität existiert die Applikation nur auf dem Papier und die Daten, die gesammelt werden können sind Schätzungen. Je weiter die Software-Entwicklung fortgeschritten ist, desto mehr quantitative Daten werden verfügbar um die Modelle kalibrieren zu können. Schließlich kann im Betrieb, das Gesamtsystem und auch der Benutzer quantitative Daten liefern. 

Im Rahmen der Masterarbeit wurde eine MOM modelliert um in Performance-Ana\-ly\-sen eingesetzt werden zu können. Dazu wurden, wie oben beschrieben, verschiedenen Daten gesammelt um das Modell kalibrieren zu können, damit eine Performance-Analyse ermöglicht wird. Dazu wurde zunächst eine bereits existierende MOM ausgewählt. Da sie sich somit im letzten Schritt der drei Software-Entwicklungsaktivitäten befindet, konnte das Gesamtsystem betrachtet und ausgemessen werden, um quantitative Daten zu sammeln. Für die Auswahl wurden zunächst in \autoref{sec:anforderungenMom} Anforderungen an die MOM definiert. Die ausgewählte MOM wird im Anschluss in \autoref{sec:rmq} vorgestellt. Die Ergebnisse der Ausmessung der MOM sind in Abschnitt \ref{sec:rmqBenchmark} beschrieben. Mithilfe der Ergebnisse, werden die Modelle in \autoref{ch:modellierung} anschließend kalibriert.


\section{Anforderungen an MOMs}
\label{sec:anforderungenMom}
Da es eine Vielzahl von MOMs gibt, muss zunächst eine Auswahl stattfinden. Dazu werden im ersten Schritt der Masterarbeit Anforderungen erarbeitet, die ein MOM erfüllen muss, damit sie in Betracht kommt. Die folgenden Anforderungen sollen erfüllt werden:
\begin{itemize}
\item Die MOM soll \textbf{Open-Source} sein.
\item Sie soll eine \textbf{weite Verbreitung} haben.
\item Die Verwendung soll \textbf{Programmiersprachen unabhängig} sein.
\item Es soll eine MOM betrachtet werden, die sich in \textbf{aktiver Entwicklung} befindet.
\item Verschiedene \textbf{Interaktionstypen} sollen unterstützt werden.
\item Sie soll einen \textbf{hohen Grad der Entkopplung}, bzgl. Raum, Zeit und Synchronisation haben.
\item Die MOM soll sowohl das Punkt-Zu-Punkt als auch Publish/Subscriber \textbf{Nachrichtenmodell} unterstützen.
\end{itemize}
%- bestimmte Protokolle unterstuetzen \\ %(https://www.predic8.de/activemq-hornetq-rabbitmq-apollo-qpid-vergleich.htm)

%\section{Auswahl der MOMs}
%In diesem Schritt sollen zwei bis drei MOMs ausgewählt werden. Dabei sollen die zuvor erarbeiteten Anforderungen einbezogen werden. Da sich bereits im Rahmen des Proposals mit dem Thema auseinander gesetzt wurde, wurden bereits drei starke Kandidaten identifiziert, die die bereits erarbeiteten Anforderungen erfüllen.
Im Folgenden wird eine MOM untersucht, die diese Anforderungen erfüllt.

\section{RabbitMQ (RMQ)}
\label{sec:rmq}
RabbitMQ (RMQ) ist, mit 35\,000 aktiven Produktivumgebungen, eine der am weitesten verbreitete MOMs. 
RMQ ist Open-Source und wird seit 2007 immer weiter entwickelt \cite{rabbitmq}. Das Ziel von RMQ ist es, allgemein einsetzbar zu sein. Deshalb wird eine Vielzahl an Protokollen unterstützt, unter anderem das JMS-Protokoll. RMQ kann auf einem zentralen Knoten oder auf mehreren verteilten Knoten eingesetzt werden. Für den Nachrichtenaustausch verwendet RMQ Warteschlangen. Diese lassen sich unterschiedlich konfigurieren, zum Beispiel in ihrer Warteschlangenlänge. Das Kommunizieren zwischen Sender und Empfänger geschieht dabei nicht direkt über die Warteschlange. Nachrichten werden zunächst an einen sogenannten \emph{Exchange} (Austausch) gesendet. Dieser ist für das richtige Weiterleiten an die passende Warteschlange verantwortlich. Dies geschieht mit Hilfe von Bindungen und Routing-Schlüsseln. In RMQ ist eine Bindung eine Verbindung zwischen einer Warteschlange und einem Exchange. RMQ unterscheidet zwischen vier verschiedenen Exchange-Typen:
\begin{itemize}
    \item \textbf{Direct}: Hierbei meldet sich eine Warteschlange mit einem bestimmten Routing-Schlüssel \texttt{X} beim Exchange an. Wenn eine Nachricht mit einem Routing-Schlüssel \texttt{Y} ankommt, wird sie nur an die Warteschlange gesendet, wenn die Routing-Schlüssel \texttt{X} und \texttt{Y} übereinstimmen.
    \item \textbf{Topic}: Die Warteschlange ist mithilfe einer Bindung mit einem Exchange verbunden. Nachrichten werden wieder anhand des Routing-Schlüssels weitergeleitet. Der Routing-Schlüssel muss nicht mehr genau passen, sondern muss ein bestimmtes Muster aufweisen.
    \item \textbf{Fanout}: Die ankommende Nachricht wird an alle mit dem Exchange verbundenen Warteschlangen gesendet. Der Routing-Schlüssel wird dabei ignoriert.
    \item \textbf{Header}: Dabei werden die Attribute des Nachrichtenkopfes verwendet, um die Nachricht weiterzuleiten.
\end{itemize}
Diese Architektur erlaubt verschiedene Interaktionstypen. Sowohl Eins-Zu-Eins als auch Viele-Zu-Viele Interaktionen sind möglich. Dabei können nicht nur mehrere Warteschlangen existieren, sondern auch mehrere Exchanges und jede der Komponenten kann auf einem anderen Knoten verteilt sein. Aufgrund dieser Architektur hat RMQ auch einen hohen Grad der Entkopplung. Denn Sender und Empfänger müssen sich nicht kennen, sie kommunizieren lediglich über den Exchange miteinander. Weder der Sender noch der Empfänger müssen zur gleichen Zeit aktiv sein. Der Sender sendet Nachrichten an die Warteschlange und der Empfänger entnimmt sie, wenn er die dazu nötigen Ressourcen zur Verfügung hat. Schließlich müssen Sender und Empfänger nicht aufeinander warten, da sie über eine Warteschlange kommunizieren.
In \autoref{img:rmq_architecture} ist ein Beispiel für eine mögliche RMQ-Architektur und Kommunikation zwischen Sendern und Empfängern dargestellt. Dabei ist \texttt{ExchangeA} vom Typ Direkt. Dieser ist mit der \texttt{Bestellungs}-Warteschlange verbunden. \texttt{ExchangeB} ist ein Topic-Exchange und mit \texttt{Bestätiguns}-Warteschlange und der \texttt{Statistik}-Warteschlange verbunden. Dabei unterscheiden sich die beiden Bindungen in ihrem Routing-Muster. \texttt{EmpfängerA} empfängt Nachrichten aus der \texttt{Bestellungs}-Warteschlange und \texttt{EmpfängerB} Nachrichten aus der \texttt{Bestätiguns}- und \texttt{Statistik}-Warteschlange. Wenn ein Sender eine Nachricht an \texttt{ExchangeA} sendet, wird diese in der \texttt{Bestellungs}-Warteschlange abgelegt, wenn der Routing-Schlüssel der Nachricht mit dem Routing-Schlüssel der Warteschlange übereinstimmt. Wenn eine Nachricht an \texttt{ExchangeB} gesendet wird, wird anhand des Routing-Musters entschieden, ob die Nachricht an die \texttt{Bestätiguns}- oder \texttt{Statistik}-Warteschlange gesendet wird. 
\begin{figure}
\center
  \includegraphics[width=1\textwidth]{images/measurement/rmqexample.pdf}
  \caption{Beispiel einer Kommunikation in RMQ}
  \label{img:rmq_architecture}
\end{figure}
%https://www.cloudamqp.com/blog/2015-05-18-part1-rabbitmq-for-beginners-what-is-rabbitmq.html

%https://www.cloudamqp.com/blog/2018-01-08-part2-rabbitmq-best-practice-for-high-performance.html
Da in dieser Arbeit der Fokus auf der Performance einer MOM liegt, wurde mithilfe von Literatur untersucht, für welche der beschriebenen Interaktionstypen, RMQ eine hohe Performance erreichen kann. Dazu konnten in \cite{rabbitmq} die folgenden Eigenschaften und Konfigurationsmöglichkeiten identifiziert werden. RMQ funktioniert am besten, wenn der Füllstand einer Warteschlange klein gehalten wird. Ein Nachricht die in eine leere Warteschlange abgelegt wird, geht direkt an einen Empfänger. Je mehr Nachrichten sich in der Warteschlange befinden, desto länger dauert es diese zu bearbeiten. Wenn der Durchsatz eine wichtige Rolle spielt und die Warteschlangen nicht voll laufen sollen, ist das Setzen einer maximalen Länge der Warteschlange oder das Setzen der Lebensdauer für Nachrichten empfohlen. Dabei bleibt die Warteschlange kurz und neue Nachrichten werden vom Kopf der Warteschlange verworfen, falls sie länger als festgelegt wird. Einen weiteren Performance-Einfluss haben Lazy-Warteschlangen. Dabei werden die Nachrichten einer Warteschlange direkt auf die Festplatte, anstatt in den Hauptspeicher, geschrieben. Das Ziel dabei ist, sehr lange Warteschlangen unterstützen zu können. Dies kann aus verschiedenen Gründen nötig sein:
\begin{itemize}
    \item Empfänger können aus verschiedenen Gründen ausfallen
    \item Plötzlicher Anstieg ankommender Nachrichten
    \item Empfänger sind langsamer als normal
\end{itemize}
Das bedeutet, dass das Hauptziel von Lazy-Warteschlangen vor allem eine hohe Zuverlässigkeit ist. Da aber die Festplatte anstatt der Hauptspeicher verwendet wird, um die Nachrichten zu verwalten, ist diese Konfiguration langsamer. Im Fall, dass Performance bevorzugt wird, sollte also auf Lazy-Warteschlangen verzichtet werden. Der Unterschied von Lazy-Warteschlangen zu persistenten Nachrichten, die auch auf die Festplatte geschrieben werden, ist das bei persistenten Nachrichten der Sender entscheidet, ob die Nachricht persistiert wird. Bei Lazy-Warteschlangen, legt der Besitzer der Warteschlange fest, welche Nachrichten persisitiert werden. Der Durchsatz von RMQ kann außerdem dadurch erhöht werden, dass mehrere Warteschlangen verwendet werden. Zum Einen kann eine einzelne Warteschlange nicht mehr als ca. 50\,000 Nachrichten bearbeiten und zum anderen sind Warteschlangen einfädig. Das heißt, dass der beste Durchsatz auf einem System möglich ist, wenn genau so viele Warteschlangen wie Kerne existieren. 

In der Folgenden Ausmessung von RMQ wurden diese und weitere Konfiguration untersucht, um zu prüfen ob sie einen messbaren Einfluss auf die Performance haben.

\section{Benchmark}
Im Rahmen der Masterarbeit wurde RMQ ausgemessen, um quantitative Daten ableiten zu können. Dazu werden in Abschnitt \ref{sec:testmachine} die Testmaschinen vorgestellt, mit denen die Messungen durchgeführt wurden. Im Anschluss werden in Abschnitt \ref{sec:rmqBenchmark} die Ergebnisse der einzelnen Messungen vorgestellt und in Abschnitt \ref{sec:rmqZusammenfassung} zusammengefasst und diskutiert.

\subsection{Testmaschinen}
\label{sec:testmachine}
Die Ausmessung wurde mit zwei virtuellen Servern durchgeführt, die von bwCloud \footnote{https://www.bw-cloud.org/} zur Verfügung gestellt wurden. Die Systemspezifikation der beiden Server ist in \autoref{tab:systespec} aufgelistet. Beide Systeme haben die gleiche Systemspezifikation und haben die RMQ Version 3.7.8 installiert. Für die Ausmessung wurden zwei Szenarien betrachtet. Der Aufbau dieser ist in \autoref{img:machineoverview} abgebildet. In \autoref{img:machineoverview}a ist der Fall zu sehen, bei dem sich Sender, Empfänger und RMQ auf der selben Maschine befinden. Damit soll RMQ unter den bestmöglichen Umständen ausgemessen werden. Dieses Szenario wird im Folgenden \textit{lokales}-Szenario bezeichnet. Das andere Szenario ist in \autoref{img:machineoverview}b zu sehen. Dabei befindet sich RMQ auf der einen Maschine und Sender und Empfänger auf der anderen. Damit sollen Netzwerkeffekte ausgemessen werden. Dieses Szenario wird im Folgenden \textit{entferntes}-Szenario bezeichnet. Die Netzwerklatenz zwischen beiden Systemen wurde durch eine zweiminütige Messung ermittelt. Die durchschnittliche Netzwerklatenz beträgt dabei 0,556 ms. 

\begin{table}
  \centering
  \begin{tabular}{|l|l|l|l|l|}
    Hauptspeicher & Festplatte & Anzahl vCPUs & GHz & Betriebssystem \\
    \hline
     4 GB & 15 GB & 2 & 2.4 GHz & Ubuntu 18.04
  \end{tabular}
	\caption{\label{tab:systespec} bwCloud VM Spezifikation}
\end{table}

\begin{figure}
\center
  \includegraphics[width=1\textwidth]{images/measurement/benchmarkSzenarioOverview.pdf}
  \caption{Die Testszenarien: \textit{lokales}- und \textit{entferntes}-Szenario.}
  \label{img:machineoverview}
\end{figure}

\subsection{Ausmessung von RMQ}
\label{sec:rmqBenchmark}
Im Folgenden wird beschrieben, wie RMQ ausgemessen wurde, um mit den Ergebnissen die Modelle kalibrieren zu können. Um RMQ auszumessen wurde das Performance-Werkzeug von RMQ benutzt\footnote{https://github.com/rabbitmq/rabbitmq-perf-test}. Dieses erlaubt es, die gesendeten und empfangenen Nachrichten und ihre Latenz zu messen. Die Latenz ist hierbei als die Zeit definiert, die eine Nachricht braucht bis sie vom Empfänger aus der Warteschlange entnommen wird, nachdem sie vom Sender dort abgelegt wurde. Das Werkzeug kann konfiguriert werden um bestimmte Szenarien zu simulieren. Unter anderem lässt sich die Anzahl der zu sendenden und zu empfangenen Nachrichten pro Sekunde einstellen. Weitere Konfigurationsmöglichkeiten sind Nachrichtengröße und die Anzahl der Sender und Empfänger. Im Folgenden sollen die Ergebnisse der Messungen vorgestellt werden. Dabei werden die einzelnen Ergebnisse und ihr Versuchsaufbau vorgestellt. Jedes Ergebnis wird wie folgt beschrieben: 
\begin{itemize}
    \item Vorstellung des Szenarios
    \item Beobachtungen des Systemverhaltens
    \item Messergebnisse
\end{itemize}
Jede Messung wurde zehn mal durchgeführt. Die einzelnen Konfiguration wurde jeweils zwei Minuten ausgeführt. 



\subsubsection{Latenz einer nicht-persistenten Nachricht}
\label{sec:oneMsgLatency}
Zunächst soll geprüft werden, wie groß die Latenz einer einzelnen, nicht persistenten, Nachricht ist. Dabei wurde auch die Größe einer Nachricht betrachtet. Dazu wurde die Senderate auf eine Nachricht pro Sekunde reduziert und die Nachrichtengröße zwischen 1 KByte und 1 MByte variiert. Für diese Messung wurde das \textit{lokale}-Szenario verwendet. Erwartet wird, dass die Latenz einer Nachricht mit ihrer Nachrichtengröße steigt.
%B
Die Ergebnisse sind in \autoref{img:senderate1-A} abgebildet. Neben den Messergebnissen ist eine Linie durch die Mediane der einzelnen Messungen gezogen. Dabei ist zu sehen, dass die Latenz einer Nachricht mit Ansteigen der Nachrichtengröße auch ansteigt. Somit verhält sich das System wie erwartet.
\begin{figure}
\center
  \includegraphics[width=0.7\textwidth]{images/measurement/rate-limit-1-A.pdf}
  \caption{Latenz einer nicht-persistenten Nachricht im \textit{lokal}-Szenario}
  \label{img:senderate1-A}
\end{figure}

Als nächstes wurde die Latenz einer Nachricht zu einer entfernten RMQ-Instanz gemessen. Dazu wurde das \textit{entfernte}-Szenario verwendet. Die Nachrichtengröße variiert zwischen 1 KByte und 1 MByte. Erwartet wird, dass zu der bereits gemessenen Latenz einer Nachricht die Netzwerklatenz dazugerechnet wird.

%B
Die Ergebnisse sind in \autoref{img:senderate1-B} zu sehen. Dabei ist durch die Mediane der einzelnen Messergebnisse eine Linie gezogen. Zu sehen ist, dass auch hier die Latenz mit Ansteigen der Nachrichtengröße wächst. Die Differenz zur vorherigen Messung entspricht der gemessenen Netzwerklatenz.
%E
Somit ist neben der Nachrichtengröße auch die Netzwerklatenz ein Faktor, der die Latenz einer Nachricht beeinflusst.

\begin{figure}
\center
  \includegraphics[width=0.7\textwidth]{images/measurement/rate-limit-1-AvsB.pdf}
  \caption{Vergleich der Latenz einer nicht-persistenten Nachricht im \textit{lokalen}- und \textit{entfernten}-Szenario}
  \label{img:senderate1-B}
\end{figure}

\subsubsection{Latenz einer persistente Nachricht}
\label{sec:persistent}
Da zuvor die Latenz nicht-persistenter Nachrichten ausgemessen wurde, wird in dieser Messung die Latenz einer persistenten Nachricht ausgemessen. Die Senderate wurde auf eine Nachricht pro Sekunde reduziert und die Nachrichtengröße zwischen 1 KByte und 1 MByte variiert. Für diese Messung wurde das \textit{lokale}-Szenario verwendet. Erwartet wird, dass die Latenz einer persistenten Nachricht größer als die einer nicht-persistenten Nachricht ist, da die Nachricht auch auf die Festplatte geschrieben wird.
%B
In \autoref{img:senderatepersisten} sind die Ergebnisse der Messung zu sehen. Außerdem wurde zu Vergleich auch die nicht-persistente Messung eingezeichnet. Wie erwartet ist die Latenz einer persistenten Nachricht größer. Der Grund hierfür ist, dass die Nachricht auch auf die Festplatte geschrieben wird, um eine Zustellung zu garantieren. Somit hat die Wahl zwischen nicht-persistenten und persistenten Nachrichten einen Einfluss auf die Performance.

\begin{figure}
\center
  \includegraphics[width=0.7\textwidth]{images/measurement/persistentVsNonPersistent.pdf}
  \caption{Latenz einer nicht-persistenten im Vergleich zu einer persistenten Nachricht.}
  \label{img:senderatepersisten}
\end{figure}
\subsubsection{Nachrichtengröße}
Da in den vorherigen Messung die Nachrichtengröße als Einflussfaktor auf die Latenz und somit die Performance identifiziert wurde, sollen im Folgenden weitere Effekte im Zusammenhang mit der Nachrichtengröße untersucht werden. Dazu wurde ein Sender und ein Empfänger eingerichtet. Beide senden und empfangen Nachrichten so schnell sie können; die oben beschriebene Limitierung der Senderate auf eine Nachricht pro Sekunde ist somit aufgehoben. Die Nachrichtengröße variiert zwischen 1 KByte und 200 KByte. Es wurde mit dem \textit{lokalen}-Szenario ausgemessen. Erwartet wird, dass sich mit zunehmender Nachrichtengröße die insgesamt pro Sekunde gesendete Nachrichtenmenge verringert. Gleichzeitig sollte der Datendurchsatz zunehmen, da die Nachrichten weniger Routing-Overhead bei RMQ verursachen.
%B
In \autoref{img:msgsize} sind die Ergebnisse dieser Messung abgebildet. Durch die jeweiligen Mediane wurde eine Linie gezogen. Die Auswirkung der Nachrichtengröße auf die Senderate ist dabei in \autoref{img:msgsize}a zu sehen. Diese nimmt, wie erwartet, mit zunehmender Größe ab. In \autoref{img:msgsize}b ist der Datendurchsatz zu sehen. Auch hier verhält sich das System wie erwartet und der Datendurchsatz nimmt zu.
\begin{figure}
\center
  \includegraphics[width=0.7\textwidth]{images/measurement/msg-rate-vs-send-bytes.pdf}
  \caption{Nachrichtenmenge und Datendurchsatz in Abhängigkeit der Nachrichtengröße.}
  \label{img:msgsize}
\end{figure}
%https://www.rabbitmq.com/blog/2012/04/25/rabbitmq-performance-measurements-part-2/

\subsubsection{Maximaler Datendurchsatz}
\label{sec:maxthroughput}
Nachdem die Effekte der zunehmende Nachrichtengröße geprüft wurden, soll nun geprüft werden wie groß der mögliche Datendurchsatz ist. Dazu wurden Nachrichten der Größe 1 KByte bis 200 KByte gesendet. Es wurden zwei Messungen durchgeführt. Im Fall der ersten Messung existiert ein Sender und kein Empfänger, bei der zweiten Messung ein Sender und ein Empfänger. Die Messung wurde mit dem \textit{lokalen}-Szenario durchgeführt. Erwartet wird, dass die Messung ohne Empfänger einen höheren Datendurchsatz ermöglicht, da diese direkt verworfen werden. 
%B
Die Ergebnisse sind in \autoref{img:maxByteThroughputA} zu sehen. Die Abbildung zeigt, dass wenn kein Empfänger vorhanden ist, mit zunehmender Nachrichtengröße der Datendurchsatz sich einen Wert von ca. 1,5 GByte pro Sekunde annähert. Wenn ein Empfänger vorhanden ist, nähert sich der Datendurchsatz an 700 MByte pro Sekunde an. Dieser Unterschied lässt sich auf den fehlenden Empfänger bzw. die fehlende Warteschlange zurückführen. Es gibt somit keinen Schreib-Overhead, da die Nachricht weder im Speicher, noch auf der Festplatte abgelegt wird.
\begin{figure}
\center
  \includegraphics[width=0.7\textwidth]{images/measurement/rate-limit-unlimited-consumer-vs-no-consumer.pdf}
  \caption{Maximaler Datendurchsatz im \textit{lokalen}-Szenario.}
  \label{img:maxByteThroughputA}
\end{figure}

%Ein weiterer Effekt ist in \autoref{img:unlimitedLatency} zu sehen. Dabei ist zu sehen, dass die Latenz sinkt wenn mehr Nachrichten auf einmal gesendet werden.
%\begin{figure}
%\center
%  \includegraphics[width=1\textwidth]{images/max-byte-throughput-A.pdf}
%  \caption{Max Datenmenge, Latenz, Testsystem A}
%  \label{img:unlimitedLatency}
%\end{figure}
%Dieser Effekt laesst sich darauf zurueckfuehren, dass wenn mehrere Nachrichten auf einmal gesendet werden der Broker weniger routing overhead hat.

Die selbe Messung wurde mit dem \textit{entfernten}-Szenario durchgeführt. Erwartet wird, dass der Datendurchsatz kleiner ist, da die Netzwerkverbindung beachtet werden muss. 
%B
Die Gegenüberstellung für den Fall, dass es einen Sender, aber keine Empfänger gibt ist in \autoref{img:maxByteThroughputNoConsumerB} zu sehen. Der Datendurchsatz an das \textit{entfernte}-System ist dabei deutlich kleiner als zuvor. Diese nähert sich dem Wert von ca. 700 MByte anstatt 1,5 GByte an. Die Messung mit Empfänger ist in \autoref{img:maxByteThroughputB} abgebildet. Auch hier ist der Datendurchsatz deutlich kleiner und nähert sich nur einem Wert von ca. 400 MByte anstatt 700 MByte an.
\begin{figure}
\center
 \includegraphics[width=0.7\textwidth]{images/measurement/rate-limit-unlimited-no-consumer-AvsB.pdf}
  \caption{Vergleich des maximalen Datendurchsatz ohne Empfänger zwischen dem \textit{lokalen}- und  \textit{entfernten}-Szenario.}
  \label{img:maxByteThroughputNoConsumerB}
\end{figure}
\begin{figure}
\center
 \includegraphics[width=0.7\textwidth]{images/measurement/rate-limit-unlimited-AvsB.pdf}
  \caption{Vergleich des maximalen Datendurchsatz mit Empfänger zwischen dem \textit{lokalen}- und  \textit{entfernten}-Szenario.}
  \label{img:maxByteThroughputB}
\end{figure}
%E
Obwohl beide Testmaschinen vom selben Anbieter sind, unterscheiden sich der mögliche Datendurchsatz zwischen einer lokalen und entfernten RMQ-Instanz. Dieser Unterschied kann auf den möglichen Datendurchsatz einer Netzwerkverbindung zurückgeführt werden. Somit ist der mögliche Datendurchsatz einer Verbindung zwischen Sender, Empfänger und RMQ ein limitierender Faktor und hat somit auch Einfluss auf die Performance des Gesamtsystems.

\subsubsection{Ansteigen des Füllstands der Warteschlange}
\label{sec:queueGrowth}
Diese Messung untersucht die Auswirkung des Warteschlangen-Füllstands auf die Latenz der einzelnen Nachrichten. Die Messung besteht aus einem Sender und einem Empfänger. Die Senderate beträgt zwei Nachrichten pro Sekunde, der Empfänger empfängt jedoch nur eine Nachricht pro Sekunde. Die Nachrichten sind dabei 1 KByte groß. Die Messung wurde mit dem \textit{lokalen}-Szenario durchgeführt. Erwartet wird, dass die Latenz der Nachrichten mit Ansteigen des Warteschlangenfüllstands wächst, da die Nachrichten länger in der Warteschlange warten, bis sie abgeholt werden.
%B
In \autoref{img:queuegrowth} sind die Messergebnisse abgebildet. Dabei ist in \autoref{img:queuegrowth}a der Füllstand der Warteschlange zu sehen. Diese wächst pro Sekunde um eine Nachricht die nicht abgeholt wird an. In \autoref{img:queuegrowth}b ist die Latenz der Nachrichten abgebildet. Wie erwartet steigt diese mit Ansteigen des Füllstands, da die Nachrichten länger in der Warteschlange warten müssen, bis sie abgeholt werden.
\begin{figure}
\center
  \includegraphics[width=0.7\textwidth]{images/measurement/queuegrowth.pdf}
  \caption{Wachstum einer Warteschlange und Auswirkung auf die Latenz.}
  \label{img:queuegrowth}
\end{figure}

\subsubsection{Konfiguration: Warteschlangenlänge begrenzen}
\label{sec:maxlength}
Die vorherige Messung hat gezeigt, dass sich das Anwachsen der Warteschlange negativ auf die Latenz der Nachrichten auswirkt. Wie bereits erwähnt erlaubt RMQ einige Konfigurationen. Eine davon ist das Setzen einer maximal Länge für Warteschlangen. Damit soll die Warteschlange kurz gehalten werden und die Latenz der Nachrichten klein. Damit wird dem Effekt, der in der vorherigen Messung untersucht wurde, entgegengewirkt. Standardmäßig wird der Kopf der Warteschlange verworfen. Mit der folgenden Messung soll diese Konfiguration untersucht werden. Dazu wurden drei Warteschlangen angelegt. Diese hatten eine maximal Länge von 100, 5000 und 50.000 Nachrichten. Die Größe von 50.000 ist die RMQ-Standardgröße für Warteschlangen. Damit man die Auswirkung auf volle Warteschlangen sehen kann wurde die Sende- und Empfangsrate entsprechend angepasst. Die Senderate wurde auf 1000 und die Empfangsrate auf 100 Nachrichten pro Sekunde eingestellt. Die Nachrichten Größe war 100 Bytes. Die Messung wurde mit dem \textit{lokalen}-Szenario durchgeführt. Erwartet wird, dass sobald die Warteschlange voll wird, die Latenz nicht mehr zu nimmt. Dieser Moment sollte schneller erreicht werden, je kleiner die Warteschlange ist.
%B
Die Ergebnisse sind in \autoref{img:maxlength} abgebildet. Wie erwartet, wachsen die Latenzen der Nachrichten bei den begrenzten Warteschlangen ab einem bestimmten Moment nicht weiter an. Wie in \autoref{img:maxlength}a und \autoref{img:maxlength}b zu sehen ist, tritt dieser Moment für die kürzere Warteschlange früher ein. In \autoref{img:maxlength}c wächst die Latenz immer weiter.
\begin{figure}
\center
  \includegraphics[width=0.7\textwidth]{images/measurement/max-length.pdf}
  \caption{Auswirkung auf die Latenz bei verschieden großen Warteschlangen.}
  \label{img:maxlength}
\end{figure}
%E
Diese Konfiguration zeigt, dass die Begrenzung der Warteschlangengröße einen Einfluss auf die Latenz hat, da man sie damit begrenzen kann. Der Nachteil dabei ist, dass Nachrichten verworfen werden, sobald die Warteschlange voll ist. Somit hat auch die Warteschlangengröße einen Einfluss auf die Performance. 

%wenn Queue voll, dann wird Msgrate angepasst

%Flow alarm ab RabbitMQ 2.8.0+ bei Versionen davor verhlaehlt sich RMQ wie in (sec: Speicher ausgeschoepft)

%\subsubsection{Speicher von RMQ ausgeschoepft}
%Nachdem in der Messung davor die Laenge der Warteschlange betrachtet wurde, soll nun untersucht werden ob der Verfuegbare Speicher des Broker einfluss auf die Performanz hat. Dazu wurde auf der Testmaschine B die Hauptspeicher fuer RMQ auf 10 MB gesetzt.  
%Sollte der verfuegbare Speicher des Broker ausgeschoepft sein, wird der MemoryAlarm aktiviert und der Broker blockiert ankommende Nachrichten, bis der Speicher wieder frei ist. Dies ist in (abb) zu sehen.
%TODO beobachtung und Ergebnis



\subsubsection{Konfiguration: Lazy-Warteschlangen}
\label{sec:rmqLazy}
Eine weitere Konfiguration die RMQ ermöglicht sind Lazy-Warteschlangen. Wie bereits erwähnt, werden dabei Nachrichten auf die Festplatte anstatt in den Hauptspeicher geschrieben. Dabei wird kein Unterschied gemacht ob die ankommenden Nachrichten persistent oder nicht-persistent sind. In der nächsten Messung soll untersucht werden ob die Konfiguration von Lazy-Warteschlangen Auswirkungen auf die Performance hat. Dabei wurde auch die Größe einer Nachricht betrachtet. Für die Messung wurde die Senderate auf eine Nachricht pro Sekunde reduziert und die Nachrichtengröße zwischen 1 KByte und 1 MByte variiert. Für diese Messung wurde das \textit{lokale}-Szenario verwendet. Erwartet wird, dass die Latenz einer Nachricht im Vergleich zu nicht-persistenten Nachrichten größer ist. 
%B
In \autoref{img:lazy} ist ein Vergleich der Messung mit nicht-persistenten und den Messergebnissen mit Lazy-Warteschlangen abgebildet. Zu sehen ist, dass die Latenz mit Lazy-Warteschlangen größer ist, als die der nicht-persistenten Nachrichten.
\begin{figure}
\center
  \includegraphics[width=0.7\textwidth]{images/measurement/lazy-queues.pdf}
  \caption{Lazy-Warteschlange im Vergleich mit nicht-persistenten Nachrichten.}
  \label{img:lazy}
\end{figure}
%E
Grund hierfür ist, dass die Nachrichten auf die Festplatte anstatt in den Hauptspeicher geschrieben werden. Somit hat diese Konfiguration einen ähnlichen Einfluss auf die Performance, wie der Einsatz persistenter Nachrichten.



\subsubsection{Mehrere Empfänger}
\label{sec:varyingConsumer}
In Abschnitt \ref{sec:queueGrowth} und \ref{sec:maxlength} war bereits zu sehen, dass volle Warteschlangen einen Einfluss auf die Latenz haben. In dieser Messung soll geprüft werden, ob es einen Unterschied macht, einen oder mehrere Empfänger eine Warteschlange abarbeiten zu lassen. Dazu wurde die Senderate eines Senders auf 1000 Nachrichten und die Empfangsrate auf 200 Nachrichten pro Sekunde limitiert. Alle Empfänger greifen auf die selbe Warteschlange zu. Außerdem wurde eine Referenzmessung mit einem Sender und einem Empfänger mit einer Sende- und Empfangsrate von 1000 durchgeführt. Die Messung wurde mit dem \textit{lokalen}-Szenario durchgeführt. Erwartet wird, dass es keinen Unterschied macht ob ein oder mehrere Empfänger eine Warteschlange abarbeiten.
%B
In \autoref{img:varyingConsumer} sind die Ergebnisse der Messung zu sehen. \autoref{img:varyingConsumer}a zeigt dabei einen Empfänger der alleine die Nachrichten empfängt. Da der Empfänger die Nachrichten nicht schnell genug empfängt, steigt die Latenz. In \autoref{img:varyingConsumer}b kommt ein weiterer Empfänger hinzu. Die Latenz wächst nicht ganz so schnell. \autoref{img:varyingConsumer}c zeigt fünf Empfänger die gemeinsam die Warteschlange abarbeiten. Im Vergleich zu der Referenzmessung in \autoref{img:varyingConsumer}d mit einem Empfänger, streut die Messung mit mehreren Empfängern stärker.
\begin{figure}
\center
  \includegraphics[width=0.9\textwidth]{images/measurement/varying-consumer.pdf}
  \caption{Verschiedene Anzahl an Empfängern mit gleicher Empfangsrate.}
  \label{img:varyingConsumer}
\end{figure}
%E
Diese stärkere Streuung lässt sich mit der Synchronisation der Empfänger erklären, die an einer gemeinsamen Warteschlange arbeiten. Da diese Streuung nicht stark ist, wird dieser Effekt im Folgenden vernachlässigt. Somit zeigt diese Messung, dass mehrere Empfänger gemeinsam an die Leistung eines einzelnen Empfängers heran kommen. 

\subsubsection{Mehrere Sender}
Diese Messung soll überprüfen, ob mehrere Sender genau so schnell die gleiche Menge an Nachrichten versenden können, wie ein einzelner. Dazu wurde als Referenz ein Sender mit einer Senderate von 5000 Nachrichten die Sekunde und fünf Sender mit jeweils 1000 Nachrichten die Sekunde untersucht. Die Messung wurde mit dem \textit{lokalen}-Szenario durchgeführt. Erwartet wird, dass es keinen Unterschied macht, ob ein Sender 5000 Nachrichten sendet oder fünf Sender jeweils 1000 Nachrichten senden. 
%B
In \autoref{img:varyingProducer} sind die Ergebnisse dieser Messung zu sehen. Dabei ist zu sehen, dass mehr Sender etwas schlechter abschneiden als ein einzelner. 
\begin{figure}
\center
  \includegraphics[width=0.7\textwidth]{images/measurement/varying-producer.pdf}
  \caption{Verschiedene Anzahl an Sendern mit gleicher Senderate.}
  \label{img:varyingProducer}
\end{figure}
%E
Auch in diesem Fall kann die höhere Latenz, der mehreren Sender, auf die Synchronisation an einer Warteschlange zurückgeführt werden. Da jedoch dieser Effekt wieder im Mikrosekunden Bereich ist, wird dieser Effekt im Folgenden für die Modellierung vernachlässigt. 
%A
%In einer weiteren Messung sollte Ausserdem geprueft werden, ob mehrere Sender ohne Sendelimit mehr Nachrichten senden koennen als ein Sender. Dazu wurde der selbe Versuchsaufbau wie oben gewaehlt mit dem Unterschied, dass diesmal die Senderate nicht eingeschraenk wurde.
%B
%In \autoref{img:varyingProducerMaxThroughput} sind die Ergebnisse dargestellt. Dabei ist zu sehen, dass die 5 Sender zusammen genauso viele Nachrichten senden wie ein Sender allein. Ausserdem ist die Latenz im Fall der 5 Sender um ein 5faches groesser als bei einem Sender.
%\begin{figure}
%\center
%  \includegraphics[width=1\textwidth]{images/varyingProducerMaxThroughput.jpg}
%  \caption{Verschiedene Sender Anzahl}
%  \label{img:varyingProducerMaxThroughput}
%\end{figure}
%E
%Das die 5 Sender jeweils nur 1/5 der moeglichen Senderate senden, kann dadurch erklaert werden, dass das Testsystem nicht mehr als eine bestimmte Rate an Nachrichten senden kann. D.h. das es keinen Unterschied macht ob ein Sender oder mehrere Sender Nachrichten senden. DIeses Verhalten kann sich aendern, wenn sich verschiedene Sender auf verschiedenen Maschinen befinden. (evtl noch Messung durchfuehren um zu zeigen) 


%Ableitung von ResourceDemands -> Regressionsfkt

%\subsection{ActiveMQ}
%ActiveMQ \cite{activeMQ} ist eine Open-Source-MOM, die seit 2004 kontinuierlich weiter entwickelt wird. ActiveMQ ist in Java geschrieben und implementiert den Java Message Service (JMS) \cite{jms}. Dabei handelt es sich um eine Programmierschnittstelle zur Ansteuerung einer MOM. Dabei soll eine lose gekoppelte, verlässliche und asynchrone Kommunikation zwischen den Komponenten einer verteilten Anwendung ermöglicht werden. ActiveMQ verfügt außerdem über mehrere Betriebsarten für hohe Verfügbarkeit und einen robusten horizontalen Skalierungsmechanismus. Darüber hinaus ist es sehr flexibel in der Konfiguration und unterstützt eine Vielzahl von Transportprotokollen, darunter auch AMQP.

\subsection{Zusammenfassung}
\label{sec:rmqZusammenfassung}
Mithilfe der durchgeführten Messungen konnten die folgenden Einflussfaktoren identifiziert werden, die einen Einfluss auf die Performance haben:
\begin{itemize}
    \item Die Nachrichtengröße hat einen Einfluss auf die Latenz einer Nachricht, die mögliche Senderate und den Datendurchsatz.
    \item Die Netzwerklatenz zwischen Sender, Empfänger und RMQ hat einen zusätzlichen Einfluss auf die Latenz einzelner Nachrichten.
    \item Der Datendurchsatz, ist durch die Netzwerkverbindung begrenzt.
    \item Wenn Nachrichten direkt aus der Warteschlange empfangen werden können, ist ihre Latenz gering.
    \item Die Latenz der Nachricht steigt, wenn die Warteschlange sich füllt und die Nachrichten in ihr warten müssen um abgeholt zu werden.
    \item Das Begrenzen der Warteschlangengröße kann die Latenz der Nachrichten klein halten.
    \item Ob Nachrichten in den Hauptspeicher oder auf die Festplatte geschrieben werden hat einen Einfluss auf die Latenz (persistente Nachrichten und Lazy-Warteschlangen).
\end{itemize}
Mithilfe dieser Einflussfaktoren soll im Folgenden ein Modell einer MOM erstellt werden, mit dem diese Einflussfaktoren abgebildet werden können. Außerdem werden die Messergebnisse dieses Kapitels verwendet um das Modell zu kalibrieren.


%RMQ hat auch Prefetch von Nachrichten. Wird nicht betrachtet (zeit und trotzdem nicht so gut wie kafka) \\
%Latenz steigt an, wenn die queue gefuellt wird \\
%- benoetigt tracken einer Nachricht durch das system \\
%- explizite Queue Modellierung, mit groesse und fuellstand \\


%--	Vergleich: https://stackshare.io/stackups/activemq-vs-kafka-vs-rabbitmq  \\


